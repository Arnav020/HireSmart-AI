- Role: Big Data Engineer

   Responsibilities:
     1. Design and implement scalable data pipelines for large-scale data processing.
     2. Optimize data storage and retrieval for performance and scalability.
     3. Work with distributed computing technologies such as Hadoop, Spark, Kafka.
     4. Ensure data security, integrity, and compliance.
     5. Collaborate with data scientists and analysts to support business needs.

   Qualifications:
     1. Degree in Computer Science, Data Engineering, or related field (Bachelor's/Master's).
     2. Experience with big data technologies including Hadoop, Spark, Kafka, and distributed computing.
     3. Proficiency in data processing languages such as SQL, Python, or Scala.
     4. Knowledge of cloud platforms like AWS, Azure, or GCP.
     5. Strong problem-solving and analytical skills.